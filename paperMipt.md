

# Стохастическая аппроксимация в непрерывном пространстве эмбеддингов для генерации дискретных инструкций.

---



### Нотация и определения (Notation and Preliminaries)

Мы рассматриваем языковую модель как функцию, отображающую последовательность непрерывных векторов (эмбеддингов) в скалярное значение функции потерь.

#### 1. Параметры Модели и Пространства
| Переменная | Размерность | Описание |
| :--- | :--- | :--- |
| $\mathcal{V}$ | $-$ | Словарь токенов (Vocabulary) языковой модели. |
| $d$ | $\in \mathbb{N}$ | Размерность эмбеддинга модели (Hidden dimension), напр. 4096 для Llama-3. |
| $\mathbf{E}$ | $|\mathcal{V}| \times d$ | Матрица эмбеддингов предобученной модели (Lookup Table). |
| $L$ | $\in \mathbb{N}$ | Фиксированная длина оптимизируемого промпта (количество токенов). |
| $f(\cdot)$ | $\mathbb{R}^{L \times d} \to \mathbb{R}$ | Функция "черного ящика" (LLM). Принимает эмбеддинги, возвращает Loss (напр., Cross-Entropy). |

#### 2. Представление Промпта (Prompt Parametrization)
| Переменная | Размерность | Описание |
| :--- | :--- | :--- |
| $\mathbf{P}$ | $L \times d$ | **Soft Prompt**. Матрица непрерывных эмбеддингов, подаваемая на вход модели. |
| $\mathbf{P}_{\text{anchor}}$ | $L \times d$ | **Опорный промпт**. Эмбеддинги реальных дискретных токенов, вокруг которых идет поиск. |
| $k$ | $\in \mathbb{N}$ | **Внутренняя размерность** (Intrinsic dimension). Размерность подпространства поиска, где $k \ll L \cdot d$. |
| $\mathbf{z}$ | $k \times 1$ | **Латентный вектор**. Параметр оптимизации в сжатом пространстве. |
| $\mathbf{A}$ | $(L \cdot d) \times k$ | **Матрица проекции**. Случайная фиксированная матрица (Random Projection Matrix), отображающая $\mathbf{z} \to \mathbf{P}$. |

#### 3. Алгоритм SPSA (Stochastic Optimization)
| Переменная | Тип | Описание |
| :--- | :--- | :--- |
| $t$ | Индекс | Номер текущей итерации оптимизации. |
| $J(\mathbf{z})$ | Скаляр | Целевая функция в латентном пространстве: $J(\mathbf{z}) = f(\mathbf{P}_{\text{anchor}} + \text{reshape}(\mathbf{A}\mathbf{z}))$. |
| $\boldsymbol{\Delta}_t$ | $k \times 1$ | **Вектор возмущения** (Perturbation vector). Сэмплируется из распределения Радемахера ($\pm 1$ с вер. 0.5). |
| $c_t$ | Скаляр | **Параметр сглаживания** (Smoothing parameter). Определяет радиус поиска градиента. |
| $\alpha_t$ | Скаляр | **Скорость обучения** (Learning rate/Step size). |
| $\hat{\nabla} J(\mathbf{z}_t)$ | $k \times 1$ | **Стохастическая оценка градиента** (SPSA Gradient Estimate). |

---

### Ключевые соотношения
Для понимания механики метода важны следующие связи:

1.  **Связь латентного и реального пространства:**
    Вектор $\mathbf{z}$ преобразуется в матрицу промпта $\mathbf{P}$ через линейную проекцию:
    $$ \mathbf{P}(\mathbf{z}) = \mathbf{P}_{\text{anchor}} + \text{View}_{L \times d}(\mathbf{A} \cdot \mathbf{z}) $$

2.  **Оценка градиента (SPSA Estimator):**
    Базируется на двух замерах функции потерь $y_\pm = J(\mathbf{z}_t \pm c_t \boldsymbol{\Delta}_t)$:
    $$ \hat{\nabla} J(\mathbf{z}_t) = \frac{y_+ - y_-}{2c_t} \cdot \boldsymbol{\Delta}_t^{-1} $$

3.  **Проекция в токены (Hard Mapping):**
    Оператор $\Pi$, возвращающий дискретные токены $T = [w_1, ..., w_L]$:
    $$ w_i = \arg\max_{v \in \mathcal{V}} \text{CosSim}(\mathbf{P}_i, \mathbf{E}_v) $$

## 1. Постановка проблемы и Мотивация

Существующие методы автоматической оптимизации промптов (APO) делятся на два лагеря, каждый из которых имеет критические недостатки:
1.  **Лингвистические агенты (MARS, OPRO):** Используют LLM для переписывания промптов. Это эвристический поиск («random walk») без гарантий сходимости, требующий огромного количества токенов.
2.  **Градиентные методы (Soft Prompts, AutoPrompt):** Требуют доступа к весам модели и обратного распространения ошибки (Backpropagation). Это невозможно для API-моделей (Black-box) и экстремально дорого по памяти для больших локальных моделей (70B+).

**Цель ZO-Prompt:** Объединить эффективность непрерывной оптимизации с доступностью black-box подхода. Мы переносим задачу из дискретного пространства токенов в непрерывное пространство эмбеддингов и применяем **SPSA (Simultaneous Perturbation Stochastic Approximation)** для навигации по ландшафту функции потерь, используя только forward-pass (прямой проход).

---

## 2. Математическая формулировка

Пусть $\mathcal{V}$ — словарь токенов, $E \in \mathbb{R}^{|\mathcal{V}| \times d}$ — матрица эмбеддингов модели.
Промпт длины $L$ представлен как матрица $P \in \mathbb{R}^{L \times d}$.
Целевая функция (Loss) $J(P)$ — это отрицательное логарифмическое правдоподобие правильного ответа (или другая метрика качества), вычисляемая LLM.

Задача оптимизации:
$$P^* = \arg\min_{P \in \mathbb{R}^{L \times d}} J(P)$$
$$\text{s.t. } \forall i \in [1, L], P_i \in \{e_v \mid v \in \mathcal{V}\}$$

Вторая строка (constraint) делает задачу комбинаторной и недифференцируемой. Мы релаксируем её, оптимизируя непрерывную матрицу $P$, и проецируем результат обратно в дискретное множество.

---

## 3. Методология: Адаптация SPSA под эмбеддинги

Классический SPSA работает с векторами. Нам нужно адаптировать его под матрицы высокой размерности ($L \times 4096$), избегая «проклятия размерности».

### Этап A: Сжатие пространства поиска (Subspace SPSA)
Поскольку полное пространство параметров ($L \cdot d \approx 10^5$) слишком велико для zero-order методов, мы используем гипотезу о низкой внутренней размерности (intrinsic dimensionality) задач NLP.

Мы оптимизируем не саму матрицу $P$, а латентный вектор $z \in \mathbb{R}^k$, где $k \ll L \cdot d$ (например, $k=500$).
$$P(z) = P_0 + \mathbf{A} \cdot z$$
Где:
*   $P_0$ — эмбеддинги исходного (написанного человеком) промпта.
*   $\mathbf{A}$ — фиксированная случайная проекционная матрица (Random Projection Matrix) из $\mathbb{R}^{k} \to \mathbb{R}^{L \cdot d}$.

Теперь наша целевая функция: $\mathcal{L}(z) = J(P_0 + \mathbf{A}z)$.

### Этап B: Оценка градиента через SPSA
На шаге $t$ мы оцениваем градиент $\hat{\nabla}\mathcal{L}(z_t)$ всего за два вызова модели (Forward Passes):

1.  Генерируем вектор возмущения $\Delta_t \sim \text{Rademacher}(\pm 1)$ размерности $k$.
2.  Вычисляем две точки в пространстве эмбеддингов:
    $$P_+ = P(z_t + c_t \Delta_t)$$
    $$P_- = P(z_t - c_t \Delta_t)$$
    *Здесь $c_t$ — параметр сглаживания.*
3.  Получаем значения функции потерь $y_+ = J(P_+)$ и $y_- = J(P_-)$ через прогон модели.
4.  Оцениваем градиент:
    $$\hat{g}_t = \frac{y_+ - y_-}{2c_t} \Delta_t^{-1} \quad (\text{для Радемахера } \Delta^{-1} = \Delta)$$

### Этап C: Обновление с инерцией (Momentum)
Для стабилизации спуска в стохастической среде используем ZO-SGD с моментумом:
$$m_{t+1} = \beta m_t + (1-\beta) \hat{g}_t$$
$$z_{t+1} = z_t - \alpha_t m_{t+1}$$

---

## 4. Проекция: От векторов к словам (Hard Prompt Projection)

Это критический этап, отсутствующий в стандартном SPSA. Нам нужно конвертировать непрерывные, оптимизированные эмбеддинги $P_{opt}$ обратно в токены, понятные человеку или API.

**Проблема:** Если проецировать на каждой итерации, мы теряем накопленную информацию градиента из-за дискретизации.
**Решение:** Стратегия **Lazy Projection** (Ленивая проекция).

1.  Мы ведем оптимизацию в непрерывном пространстве $z$ в течение $T_{proj}$ шагов.
2.  Каждые $T_{proj}$ итераций выполняем "Soft-to-Hard" проекцию:
    $$\text{Tokens} = \text{NearestNeighbor}(P(z), \mathcal{V})$$
    Для каждого вектора $v_i$ в промпте ищем токен $w$ с максимальным косинусным сходством:
    $$w = \arg\max_{v' \in E} \frac{v_i \cdot v'}{\|v_i\| \|v'\|}$$
3.  **Реинициализация (Anchor Reset):** Чтобы не уйти слишком далеко от языка, мы обновляем "опорную точку" $P_0$ на эмбеддинги найденных токенов и сбрасываем $z$ в ноль. Это гарантирует, что мы оптимизируем *вокруг* реальных слов.

---

## 5. Теоретическое обоснование (Ваш вклад)

Здесь вы применяете свой бэкграунд для доказательства надежности метода.

### Утверждение 1: Несмещенность оценки (Smoothing)
Мы оптимизируем не разрывную функцию $J(P)$, а её Гауссово сглаживание $J_\mu(P)$. Оценка градиента $\hat{g}_t$, полученная через SPSA, является несмещенной оценкой градиента сглаженной функции:
$$\mathbb{E}[\hat{g}_t] = \nabla J_{c_t}(z_t)$$

### Утверждение 2: Сходимость (Convergence Rate)
Для невыпуклой L-гладкой функции потерь (каковой является нейросеть), алгоритм ZO-Prompt с learning rate $\alpha_t = \frac{\alpha}{\sqrt{t}}$ сходится к стационарной точке со скоростью:
$$\frac{1}{T} \sum_{t=1}^T \mathbb{E}\|\nabla J(z_t)\|^2 \leq \mathcal{O}\left(\frac{\sqrt{k}}{\sqrt{T}}\right)$$
Где $k$ — размерность подпространства оптимизации.
Это доказывает, что сжатие пространства ($k \ll L \cdot d$) критически важно для сходимости за разумное время.

---

## 6. Псевдокод алгоритма

```python
Algorithm ZO-Prompt(Prompt_0, Model, Vocab):
    # Инициализация
    P_anchor = Embed(Prompt_0) # [L, D]
    z = zeros(k) # Латентный вектор оптимизации
    A = RandomMatrix(k, L*D) # Проекция
    
    for t in range(MaxSteps):
        # 1. Генерация шума
        Delta = Rademacher(k) 
        
        # 2. Прямой проход (Forward Pass)
        # Формируем "мягкие" промпты
        P_plus = P_anchor + Reshape(A @ (z + c * Delta))
        P_minus = P_anchor + Reshape(A @ (z - c * Delta))
        
        # Получаем Loss (без градиентов!)
        L_plus = Model.forward(inputs_embeds=P_plus).loss
        L_minus = Model.forward(inputs_embeds=P_minus).loss
        
        # 3. Оценка градиента SPSA
        grad_est = (L_plus - L_minus) / (2 * c) * Delta
        
        # 4. Обновление параметров
        z = z - alpha * grad_est
        
        # 5. Ленивая проекция (Раз в N шагов)
        if t % ProjectionInterval == 0:
             P_current = P_anchor + Reshape(A @ z)
             # Находим ближайшие реальные токены
             DiscreteTokens = NearestNeighbor(P_current, Vocab)
             # Обновляем якорь, сбрасываем z
             P_anchor = Embed(DiscreteTokens)
             z = zeros(k)
             
    return Decode(P_anchor)
```

## 7. Почему это лучше MARS?

1.  **Память:** Требует в $O(L)$ меньше памяти, чем градиентные методы (Backprop), так как не хранит граф вычислений.
2.  **Строгость:** В отличие от MARS, который полагается на "удачу" при генерации текста агентом-учителем, ZO-Prompt математически гарантированно движется в сторону уменьшения ошибки (в матожидании).
3.  **Универсальность:** Работает с любой дифференцируемой моделью (Llama, Mistral, BERT) и легко адаптируется для Black-Box атак или настройки API (если есть доступ к log-probs).
